{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2020-10-19 20:16:17,532: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    }
   ],
   "source": [
    "# Set up libraries and backend\n",
    "from qiskit.tools.jupyter import * \n",
    "from qiskit import IBMQ\n",
    "from qiskit import assemble\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import pulse\n",
    "from qiskit.pulse import pulse_lib\n",
    "from qiskit.pulse import Play\n",
    "from qiskit.pulse.commands import SamplePulse\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from scipy.optimize import curve_fit\n",
    "import json\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q', group='open', project='main')\n",
    "backend = provider.get_backend('ibmq_armonk')\n",
    "backend_config = backend.configuration()\n",
    "assert backend_config.open_pulse, \"Backend doesn't support OpenPulse\"\n",
    "\n",
    "# Use for conversions later\n",
    "GHz = 1.0e9\n",
    "MHz = 1.0e6\n",
    "kHz = 1.0e3\n",
    "ms = 1.0e-3\n",
    "us = 1.0e-6\n",
    "ns = 1.0e-9\n",
    "scale_factor = 1e-14\n",
    "\n",
    "# Initialize qubit to |0> and retrieve backend frequencies\n",
    "qubit = 0\n",
    "dt = backend_config.dt\n",
    "backend_defaults = backend.defaults()\n",
    "qubit_props_dict = backend.properties().qubit_property(0)\n",
    "rough_qubit_freq = qubit_props_dict['frequency'][0]\n",
    "rough_cav_freq = backend_defaults.meas_freq_est[qubit]\n",
    "\n",
    "\n",
    "# Define and configure measurement map (hardware constraint)\n",
    "meas_map_idx = None\n",
    "for i, measure_group in enumerate(backend_config.meas_map):\n",
    "    if qubit in measure_group:\n",
    "        meas_map_idx = i\n",
    "        break\n",
    "assert meas_map_idx is not None, f\"Couldn't find qubit {qubit} in meas_map!\"\n",
    "drive_chan = pulse.DriveChannel(qubit)\n",
    "meas_chan = pulse.MeasureChannel(qubit)\n",
    "acq_chan = pulse.AcquireChannel(qubit)\n",
    "qubit_meas_group = backend_config.meas_map[meas_map_idx]\n",
    "inst_sched_map = backend_defaults.instruction_schedule_map\n",
    "measure = inst_sched_map.get('measure', qubits=qubit_meas_group)\n",
    "\n",
    "\n",
    "# Define for convenience\n",
    "def get_closest_multiple_of_16(num):\n",
    "     return int(num + 8) - (int(num + 8) % 16)\n",
    "\n",
    "# Functions to save data to and load data from external text files\n",
    "def saveData(dataset, file):\n",
    "    filehandler = open(file, 'w')\n",
    "    json.dump(dataset, filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "def loadData(file):\n",
    "    filehandler = open(file)\n",
    "    data = json.load(filehandler)\n",
    "    filehandler.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cavity frequency based on calibration experiment\n",
    "cavity_data = loadData('CavityParameters.txt')\n",
    "cav_freq_Hz = cavity_data['wc']\n",
    "cav_freq_GHz = cav_freq_Hz / GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement + acquisition parameters\n",
    "meas_amp = 0.3\n",
    "acq_samp_us = 0.05\n",
    "meas_sigma_us = 0.01\n",
    "meas_risefall_us = 0.01\n",
    "\n",
    "acq_samp = get_closest_multiple_of_16(acq_samp_us * us/dt)\n",
    "meas_sigma = get_closest_multiple_of_16(meas_sigma_us * us/dt)\n",
    "meas_risefall = get_closest_multiple_of_16(meas_risefall_us * us/dt)\n",
    "\n",
    "meas_pulse = pulse_lib.gaussian_square(amp=meas_amp, duration=acq_samp, sigma=meas_sigma, risefall=meas_risefall)\n",
    "acq_pulse = pulse.Acquire(duration=acq_samp, channel=[pulse.AcquireChannel(i) for i in qubit_meas_group],\n",
    "                         mem_slot=[pulse.MemorySlot(i) for i in qubit_meas_group])\n",
    "\n",
    "# Create schedule for measurement\n",
    "meas_schedule = pulse.Schedule(name='Measurement schedule')\n",
    "meas_schedule += Play(meas_pulse, meas_chan)\n",
    "meas_schedule += acq_pulse\n",
    "\n",
    "# Split cavity drives into 2 diff jobs in order to maximize drive amplitude without exceeding memory restrictions\n",
    "\n",
    "# Lower cavity drive job\n",
    "cav_dur_min_us_0 = 1.0\n",
    "cav_dur_max_us_0 = 9.0\n",
    "num_durs_0 = 10\n",
    "\n",
    "# Higher cavity drive job (less data points allowed since higher drive times --> greater memory per pulse)\n",
    "cav_dur_min_us_1 = 9.0\n",
    "cav_dur_max_us_1 = 13.0\n",
    "num_durs_1 = 5\n",
    "\n",
    "# Maximal amplitude --> adjusting this would allow for adjustment of duration ranges above\n",
    "cav_amp = 1.0\n",
    "\n",
    "cav_durs_us_0 = np.linspace(cav_dur_min_us_0, cav_dur_max_us_0, num_durs_0, endpoint=True)\n",
    "cav_durs_us_1 = np.linspace(cav_dur_min_us_1, cav_dur_max_us_1, num_durs_1, endpoint=True)\n",
    "cav_durs_0 = [get_closest_multiple_of_16(dur_us * us/dt) for dur_us in cav_durs_us_0]\n",
    "cav_durs_1 = [get_closest_multiple_of_16(dur_us * us/dt) for dur_us in cav_durs_us_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pi pulse parameters from calibration experiment, construct pulse\n",
    "\n",
    "pi_data = loadData('pipulse.txt') # from calibration experiment\n",
    "drive_samps_us = pi_data['drive_samps_us'] # Width of the gaussian pulse\n",
    "drive_sigma_us = pi_data['drive_sigma_us'] # Truncates duration of gaussian to be finite\n",
    "pi_amp = pi_data['pi_amp']\n",
    "\n",
    "drive_samps = get_closest_multiple_of_16(drive_samps_us * us/dt) # Puts width in units of dt\n",
    "drive_sigma = get_closest_multiple_of_16(drive_sigma_us * us/dt) # Puts duration in units of dt\n",
    "\n",
    "pi_pulse = pulse_lib.gaussian(amp=pi_amp, sigma=drive_sigma, duration=drive_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground and excited schedules where each has different location of acquisition during drive\n",
    "\n",
    "schedules_gnd_0 = []\n",
    "for dur in cav_durs_0:\n",
    "    cav_pulse = pulse_lib.gaussian_square(amp=cav_amp, duration=dur, sigma=meas_sigma, risefall=meas_risefall)\n",
    "    schedule = pulse.Schedule(name=f\"Cav duration {dur} (dt)\")\n",
    "    schedule += Play(cav_pulse, meas_chan)\n",
    "    schedule += meas_schedule\n",
    "    schedules_gnd_0.append(schedule)\n",
    "    \n",
    "schedules_gnd_1 = []\n",
    "for dur in cav_durs_1:\n",
    "    cav_pulse = pulse_lib.gaussian_square(amp=cav_amp, duration=dur, sigma=meas_sigma, risefall=meas_risefall)\n",
    "    schedule = pulse.Schedule(name=f\"Cav duration {dur} (dt)\")\n",
    "    schedule += Play(cav_pulse, meas_chan)\n",
    "    schedule += meas_schedule\n",
    "    schedules_gnd_1.append(schedule)\n",
    "    \n",
    "schedules_exc_0 = []\n",
    "for dur in cav_durs_0:\n",
    "    cav_pulse = pulse_lib.gaussian_square(amp=cav_amp, duration=dur, sigma=meas_sigma, risefall=meas_risefall)\n",
    "    schedule = pulse.Schedule(name=f\"Cav duration {dur} (dt)\")\n",
    "    schedule += Play(pi_pulse, drive_chan)\n",
    "    schedule += Play(cav_pulse, meas_chan) << schedule.duration\n",
    "    schedule += meas_schedule\n",
    "    schedules_exc_0.append(schedule)\n",
    "    \n",
    "schedules_exc_1 = []\n",
    "for dur in cav_durs_1:\n",
    "    cav_pulse = pulse_lib.gaussian_square(amp=cav_amp, duration=dur, sigma=meas_sigma, risefall=meas_risefall)\n",
    "    schedule = pulse.Schedule(name=f\"Cav duration {dur} (dt)\")\n",
    "    schedule += Play(pi_pulse, drive_chan)\n",
    "    schedule += Play(cav_pulse, meas_chan) << schedule.duration\n",
    "    schedule += meas_schedule\n",
    "    schedules_exc_1.append(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: job incurred error     \n",
      "Job gnd 0 error: Internal Error. Error code: 9999.\n",
      "Job Status: job incurred error     \n",
      "Job gnd 1 error: Internal Error. Error code: 9999.\n",
      "Job Status: job incurred error     \n",
      "Job exc 0 error: Internal Error. Error code: 9999.\n",
      "Job Status: job incurred error     \n",
      "Job exc 1 error: Internal Error. Error code: 9999.\n"
     ]
    }
   ],
   "source": [
    "# Number of shots performed in each Qobj\n",
    "num_shots = 1024\n",
    "\n",
    "program_gnd_0 = assemble(schedules_gnd_0, backend=backend, shots=num_shots,\n",
    "                       meas_level=1, meas_return='avg', schedule_los=[{meas_chan: cav_freq_Hz}]*len(schedules_gnd_0))\n",
    "\n",
    "program_gnd_1 = assemble(schedules_gnd_1, backend=backend, shots=num_shots,\n",
    "                       meas_level=1, meas_return='avg', schedule_los=[{meas_chan: cav_freq_Hz}]*len(schedules_gnd_1))\n",
    "                       \n",
    "program_exc_0 = assemble(schedules_exc_0, backend=backend, shots=num_shots,\n",
    "                      meas_level=1, meas_return='avg', schedule_los=[{meas_chan: cav_freq_Hz}]*len(schedules_exc_0))\n",
    "\n",
    "program_exc_1 = assemble(schedules_exc_1, backend=backend, shots=num_shots,\n",
    "                      meas_level=1, meas_return='avg', schedule_los=[{meas_chan: cav_freq_Hz}]*len(schedules_exc_1))\n",
    "\n",
    "job_gnd_0 = backend.run(program_gnd_0)\n",
    "jobID_gnd_0 = job_gnd_0.job_id()\n",
    "job_monitor(job_gnd_0)\n",
    "print(f\"Job gnd 0 error: {job_gnd_0.error_message()}\")\n",
    "\n",
    "job_gnd_1 = backend.run(program_gnd_1)\n",
    "jobID_gnd_1 = job_gnd_1.job_id()\n",
    "job_monitor(job_gnd_1)\n",
    "print(f\"Job gnd 1 error: {job_gnd_1.error_message()}\")\n",
    "\n",
    "job_exc_0 = backend.run(program_exc_0)\n",
    "jobID_exc_0 = job_exc_0.job_id()\n",
    "job_monitor(job_exc_0)\n",
    "print(f\"Job exc 0 error: {job_exc_0.error_message()}\")\n",
    "\n",
    "job_exc_1 = backend.run(program_exc_1)\n",
    "jobID_exc_1 = job_exc_1.job_id()\n",
    "job_monitor(job_exc_1)\n",
    "print(f\"Job exc 1 error: {job_exc_1.error_message()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Internal Error. Error code: 9999.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IBMQJobFailureError",
     "evalue": "'Unable to retrieve result for job 5f8e2c56dc47090013ed1b1b. Job has failed. Use job.error_message() to get more details.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIBMQJobFailureError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-448db6527c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata_gnd_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_job_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_gnd_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdata_gnd_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_job_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_gnd_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata_exc_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_job_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_exc_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-448db6527c6f>\u001b[0m in \u001b[0;36mget_job_data\u001b[0;34m(job)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function for quickly extracting results from jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_job_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newerQiskit/lib/python3.7/site-packages/qiskit/providers/ibmq/job/ibmqjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, wait, partial, refresh)\u001b[0m\n\u001b[1;32m    272\u001b[0m                 raise IBMQJobFailureError(\n\u001b[1;32m    273\u001b[0m                     \u001b[0;34m'Unable to retrieve result for job {}. Job has failed. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                     'Use job.error_message() to get more details.'.format(self.job_id()))\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIBMQJobFailureError\u001b[0m: 'Unable to retrieve result for job 5f8e2c56dc47090013ed1b1b. Job has failed. Use job.error_message() to get more details.'"
     ]
    }
   ],
   "source": [
    "# Function for quickly extracting results from jobs\n",
    "def get_job_data(job):\n",
    "    result = job.result(timeout=120)\n",
    "    sweep = []\n",
    "    for i in range(len(result.results)):\n",
    "        res = result.get_memory(i)*scale_factor\n",
    "        sweep.append(res[qubit])\n",
    "    return sweep\n",
    "\n",
    "# Retrieve data\n",
    "data_gnd_0 = get_job_data(job_gnd_0)\n",
    "data_gnd_1 = get_job_data(job_gnd_1)\n",
    "data_exc_0 = get_job_data(job_exc_0)\n",
    "data_exc_1 = get_job_data(job_exc_1)\n",
    "\n",
    "# Datasets in diff jobs are off by diff phases --> \n",
    "# use overlap data point (@dur = 9.0 us) in gnd and exc datasets to shift accordingly for each pair\n",
    "phase_gnd = data_gnd_1[0] - data_gnd_0[-1]\n",
    "phase_exc = data_exc_1[0] - data_exc_0[-1]\n",
    "shifted_data_gnd_1 = data_gnd_1 - phase_gnd\n",
    "shifted_data_exc_1 = data_exc_1 - phase_exc\n",
    "\n",
    "# Concatenate datasets to use as whole\n",
    "data_gnd = data_gnd_0 + shifted_data_gnd_1\n",
    "data_exc = data_exc_0 + shifted_data_exc_1\n",
    "cav_durs_us = np.concatenate((cav_durs_us_0, cav_durs_us_1))\n",
    "\n",
    "# Plot evolution of data over total time cavity driven\n",
    "plt.scatter(cav_durs_us, np.abs(data_gnd), color='black')\n",
    "plt.scatter(cav_durs_us, np.real(data_gnd), color='blue')\n",
    "plt.scatter(cav_durs_us, np.imag(data_gnd), color='red')\n",
    "plt.xlabel(\"Cavity drive time [us]\")\n",
    "plt.ylabel(\"Quadrature [au]\")\n",
    "plt.title(\"Ground State Stabilization over Time Driven\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(cav_durs_us, np.abs(data_exc), color='black')\n",
    "plt.scatter(cav_durs_us, np.real(data_exc), color='blue')\n",
    "plt.scatter(cav_durs_us, np.imag(data_exc), color='red')\n",
    "plt.xlabel(\"Cavity drive time [us]\")\n",
    "plt.ylabel(\"Quadrature [au]\")\n",
    "plt.title(\"Excited State Stabilization over Time Driven\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot evolution of quadrature components over time (black is first point in time, red is last)\n",
    "\n",
    "plt.scatter(np.real(data_gnd), np.imag(data_gnd), color='blue')\n",
    "plt.scatter(np.real(data_gnd[0]), np.imag(data_gnd[0]), color='black')\n",
    "plt.scatter(np.real(data_gnd[-1]), np.imag(data_gnd[-1]), color='red')\n",
    "plt.xlabel(\"I [au]\")\n",
    "plt.ylabel(\"Q [au]\")\n",
    "plt.title(\"Quadratures of Ground State\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(np.real(data_exc), np.imag(data_exc), color='blue')\n",
    "plt.scatter(np.real(data_exc[0]), np.imag(data_exc[0]), color='black')\n",
    "plt.scatter(np.real(data_exc[-1]), np.imag(data_exc[-1]), color='red')\n",
    "plt.xlabel(\"I [au]\")\n",
    "plt.ylabel(\"Q [au]\")\n",
    "plt.title(\"Quadratures of Excited State\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
